log(captures$weight_g)
# Divide weight by the foot length and save the new variable as wfratio
wfratio <- captures$weight_g/captures$footlength_mm
# add the column wfratio to the captures data frame, creating a new data frame called captures.new
captures.new <- cbind(captures, wfratio) # using R base function `cbind`
?cbind
captures %>%
mutate(wfratio = weight_g/footlength_mm) -> captures.new
head(captures.new)
# remove the data frame captures.new from the working environment
rm(captures.new)
# now add both the log of the weight and the column wfratio to the captures data frame, creating again new data frame called captures.new
captures %>%
mutate(logw = log(weight_g),
wfratio = weight_g/footlength_mm) -> captures.new
head(captures.new)
# DO IT ON YOUR OWN - ADD ANOTHER VARIABLE TO THE DATA FRAME, E.G. YEAR + 1
captures %>%
mutate(wrongyear=year+1)->captures.new
head(captures.new)
rm(captures.new)
# filter data selecting only weights < 25
filter(captures, weight_g == 25)
# filter data selecting only weights < 25
filter(captures, weight_g < 25)
# filter data selecting only weights < 25
filter(captures, weight_g == 25)
# filter data selecting only weights < 25, but not... really, it gives me weight = to 25
filter(captures, weight_g = 25)
# filter data selecting only weights < 25, but not... really, it gives me weight = to 25
filter(captures, weight_g == 25)
# filter data selecting only weights < 25
filter(captures, weight_g< 25)
# filter data selecting only weights < 25 or > 40
filter(captures, weight_g < 25 | weight_g > 40)
# filter data selecting only weights > 40 and foot length > 18
filter(captures, footlength_mm > 18 & weight_g > 40)
# filter data selecting only weights < 25
filter(captures$weight_g<25)
# filter data selecting only weights < 25
filter(captures, weight_g<25)
# filter data selecting only weights < 25 or > 40
filter(captures, weight_g<25 | weight_g>40)
# filter data selecting only weights > 40 and foot length > 18
filter(captures, weight_g>40 & footlenght_mm>18)
# filter data selecting only weights > 40 and foot length > 18
filter(captures, weight_g>40 & footlength_mm>18)
# DO IT ON YOUR OWN - SELECT ONLY CAPTURES RECORDED AFTER DOY 210
filter(captures, DOY>210)
# SELECT ONLY CAPTURES RECORDED IN JULY
filter(captures, month==7)
# select columns by name
captures %>%
select(weight_g, sex, age, footlength_mm)
# select all columns between weight and age
captures %>%
select(weight_g:age)
# select all columns except dawn
captures %>%
select(-(dawn))
# select all columns except those from animal_id to furmark
captures %>%
select(-(animal_id:furmark))
# select columns from weight_g to footlenght_mm, excluding reproductive status
captures %>%
select(weight_g:footlength_mm) %>%
select(-repr_status)
captures %>%
group_by(sex) %>%
summarise(mean(weight_g, na.rm=TRUE))
summarise(mean.w = (mean(na.omit(weight_g)))
# DO IT ON YOUR OWN - CALCULATE THE MEAN TAKING INTO ACCOUNT THE AGE CLASS
# DO IT ON YOUR OWN - CALCULATE THE MEAN TAKING INTO ACCOUNT THE AGE CLASS
captures %>%
# DO IT ON YOUR OWN - CALCULATE THE MEAN TAKING INTO ACCOUNT THE AGE CLASS
captures %>%
group_by(age) %>%
summarise(mean.w = (mean(na.omit(weight_g))))
captures %>%
group_by(age, sex) %>%
summarise(mean(weight_g, na.rm=TRUE))
captures %>%
group_by(age, sex) %>%
summarise(mw = mean(weight_g, na.rm=TRUE), mf = mean(footlength_mm, na.rm=TRUE))
# or:
captures %>%
group_by(sex) %>%
summarise(mean(weight_g, na.rm=TRUE)) %>%
ungroup()
# sort the weigth of the animals
sort(captures$weight_g)
sort(captures$weight_g, decreasing = TRUE)
captures %>%
arrange(weight_g)
captures %>%
arrange(desc(weight_g))
# DO IT ON YOUR OWN - ARRANGE THE DATA FRAME ACCORDING TO FOOT LEGTH, BOTH IN ASCENDING AND DESCENDING ORDER
captures %>%
arrange(footlength_mm)
# DO IT ON YOUR OWN - ARRANGE THE DATA FRAME ACCORDING TO FOOT LEGTH, BOTH IN ASCENDING AND DESCENDING ORDER
captures %>%
arrange(desc(footlength_mm))
# DO IT ON YOUR OWN
?arrange
captures %>%
group_by(age)
# DO IT ON YOUR OWN
?arrange
captures %>%
group_by(age) %>%
arreange(weigth_g, .by_group =TRUE)
captures %>%
group_by(age) %>%
arrange(weigth_g, .by_group =TRUE)
captures %>%
group_by(age) %>%
arrange(weight_g, .by_group =TRUE)
# order according to weight and then to footlenght
captures %>%
arrange(desc(weight_g), footlength_mm)
library(Rmisc)
install.packages("Rmisc")
library(Hmisc)
install.packages("Hmisc")
library(ggplot2)
library(boot)
dati <- read.csv("data/captures.csv", sep=";")
CI(dati$weight_g, ci=0.95)
CI(na.omit(dati$weight_g), ci=0.95)
library(Rmisc)
library(Rmisc)
library(Hmisc)
library(ggplot2)
library(boot)
CI(dati$weight_g, ci=0.95)
CI(na.omit(dati$weight_g), ci=0.95)
dati2 <- na.omit(dati)
group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
dati2 <- na.omit(dati)
group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli <- group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli
ggplot(intervalli, aes(x=sex, y=weight_g.mean, colour=sex)) +
geom_errorbar(aes(ymin=weight_g.lower, ymax=weight_g.upper), width=.1) +
geom_line() +
geom_point()
intervalli <- group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli
group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
CI(na.omit(dati$footlength_mm), ci=0,95)
CI(na.omit(dati$footlength_mm), ci=0.95)
CI(dati2$footlength_mm, ci=0.95)
CI(na.omit(dati$footlength_mm), ci=0.95)
CI(dati2$footlength_mm, ci=0.95)
dati2 <- na.omit(dati)
CI(dati2$footlength_mm, ci=0.95)
CI(na.omit(dati$footlength_mm), ci=0.95)
names(dati2)
intervalli <- group.CI(footlength_mm ~ sex,
data= dati2,
ci=0.95)
intervalli <- group.CI(footlength_mm ~ sex,
data= dati2,
ci=0.95)
intervalli
ggplot(intervalli, aes(x=sex, y=footlength_mm.mean, colour=sex)) +
geom_errorbar(aes(ymin=footlength_mm.lower, ymax=footlength_mm.upper), width=.1) +
geom_line() +
geom_point()
intervalli
ggplot(intervalli, aes(x=sex, y=footlength_mm.mean, colour=sex)) +
geom_errorbar(aes(ymin=footlength_mm.lower, ymax=footlength_mm.upper), width=.1) +
geom_line() +
geom_point()
variablile <- dati2$footlength_mm
intervalli <- group.CI(variablile ~ sex,
data= dati2,
ci=0.95)
intervalli
ggplot(intervalli, aes(x=sex, y=variablile.mean, colour=sex)) +
geom_errorbar(aes(ymin=variablile.lower, ymax=variablile.upper), width=.1) +
geom_line() +
geom_point()
boot.data <- boot(dati2$weight_g,
function(x,i) mean(x[i]),
R=10000)
boot.ci(boot.data,
conf = 0.95)
library(tidyverse)
dati2 %>%
filter(sex == "F") -> datiF
dati2 %>%
filter(sex == "M") -> datiM
dataset<-datiF
boot.data <- boot(dataset$weight_g,
function(x,i) mean(x[i]),
R=10000)
boot.ci(boot.data,
conf = 0.95)
d
dati2 %>%
filter(sex == "M") -> datiM
dataset<-datiF
boot.data <- boot(dataset$weight_g,
function(x,i) mean(x[i]),
R=10000)
library(dplyr)
captures <- read.csv("data/captures.csv", sep=";")
captures %>%
filter(age=="A") -> adults
head(adults)
adults %>%
group_by(animal_id, sex) -> grouped
grouped %>%
arrange(animal_id)
grouped %>%
summarise(count=n(), individual.weight = mean(weight_g, na.rm = TRUE)) -> ind.w
ind.w
#?qqplot
qqnorm(ind.w$individual.weight); qqline(ind.w$individual.weight, col="red")
shapiro.test(ind.w$individual.weight)
t.test(ind.w$individual.weight, mu = 30)
t.test(ind.w$individual.weight, mu = 30)
library(dplyr)
captures <- read.csv("data/captures.csv", sep=";")
captures %>%
filter(age=="A") -> adults
head(adults)
t.test(ind.w$individual.weight, mu = 30)
adults %>%
group_by(animal_id, sex) -> grouped
grouped %>%
arrange(animal_id)
grouped %>%
summarise(count=n(), individual.weight = mean(weight_g, na.rm = TRUE)) -> ind.w
ind.w
t.test(ind.w$individual.weight, mu = 30)
## is the weight of females and males different?
# we use again the summarise dplyr function
ind.w %>%
group_by(sex) %>%
summarise(count=n(), class.weight = mean(individual.weight, na.rm = TRUE))
# again, if you could not install dplyr, use the following code
# tapply(ind.w$individual.weight, ind.w$sex, mean, na.rm = TRUE)
# We can see the difference in weight that we observe between males and females
w.f <- (subset(ind.w, sex=="F"))$individual.weight
w.m <- (subset(ind.w, sex=="M"))$individual.weight
## is the weight of females and males different?
# we use again the summarise dplyr function
ind.w %>%
group_by(sex) %>%
summarise(count=n(), class.weight = mean(individual.weight, na.rm = TRUE))
# again, if you could not install dplyr, use the following code
# tapply(ind.w$individual.weight, ind.w$sex, mean, na.rm = TRUE)
# We can see the difference in weight that we observe between males and females
w.f <- (subset(ind.w, sex=="F"))$individual.weight
w.m <- (subset(ind.w, sex=="M"))$individual.weight
# we use again the summarise dplyr function
ind.w %>%
group_by(sex) %>%
summarise(count=n(), class.weight = mean(individual.weight, na.rm = TRUE))
# We can see the difference in weight that we observe between males and females
w.f <- (subset(ind.w, sex=="F"))$individual.weight
w.m <- (subset(ind.w, sex=="M"))$individual.weight
w.f
w.m
w.f
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.f); qqline(w.f, col="red")
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.f); qqline(w.f, col="red")
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.f); qqline(w.f, col="red")
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.m); qqline(w.m, col="red")
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.f); qqline(w.f, col="red")
shapiro.test(w.f)
shapiro.test(w.m)
var(w.f, na.rm = T)
var(w.m, na.rm = T)
var.test(w.f,w.m)
var(w.f, na.rm = T)
var(w.m, na.rm = T)
var.test(w.f,w.m)
var(w.f, na.rm = T)/var(w.m, na.rm = T)
boxplot(ind.w$individual.weight ~ ind.w$sex)
# ?t.test
t.test(w.f, w.m,
var.equal = TRUE,
paired = FALSE,
alternative = "two.sided") # greater/less
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# homogeneity of variances
var.test(x,y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
library(readr)
captures <- read_csv("data/captures.csv")
View(captures)
library(readr)
captures <- read_delim("data/captures.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
View(captures)
cars.lm <- lm(dist ~ speed, data = cars)
names(cars.lm)
coef(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
summary(cars.lm)
fitted(cars.lm)
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
carsumry$sigma
summary(cars.lm)
# new <- data.frame(speed = c(5,6,21))
# predict(cars.lm, newdata = new, interval = "confidence")
# predict(cars.lm, newdata = new, interval = "prediction")
library(HH)
ci.plot(cars.lm)
# or
# library(UsingR)
# simple.lm(cars$speed, cars$dist, show.ci=TRUE)
t = (-1.1583 - (-1.5))/0.2236
pt(t, 7, lower.tail = FALSE)
t = (-1.1583 - (-1.5))/0.2236
pt(t, 7, lower.tail = FALSE)
plot(cars.lm)
data(cars)
cars.lm <- lm(dist ~ speed, data = cars)
coef(cars.lm)
names(cars.lm)
residuals(cars.lm)
residuals(cars.lm)
par(mfrow=c(1,3))
hist(residuals(cars.lm))
boxplot(residuals(cars.lm))
qqnorm(residuals(cars.lm))
qqline(residuals(cars.lm))
par(mfrow=c(1,1))
plot(cars.lm)
# install.packages("lmtest")
library(lmtest)
dwtest(cars.lm, alternative = "two.sided")
library(lmtest)
bptest(cars.lm)
library(MASS)
hist(trees$Volume^0.31)
```{r problem8.6-normality-girth}
# load the data
data(trees) # this is a dataframe
class(trees)
head(trees)
str(trees)
# histograms
hist(trees$Girth)
hist(trees$Height)
hist(trees$Volume)
# boxplots
boxplot(trees$Girth)
boxplot(trees$Height)
boxplot(trees$Volume)
# normality test
shapiro.test(trees$Girth)
qqnorm(trees$Girth); qqline(trees$Girth)
# normality test
shapiro.test(trees$Height)
qqnorm(trees$Height); qqline(trees$Height)
# normality test
shapiro.test(trees$Volume)
qqnorm(trees$Volume); qqline(trees$Volume)
data("trees")
mod <- lm(Volume ~ Girth + Height, data=trees)
summary(mod)
# the mean increase in volume when there is a one-unit increase in girth is 4.7
# Volume.tr <- trees$Volume^0.30
# mod.tr <- lm(Volume.tr ~ Girth + Height, data=trees)
# summary(mod.tr)
plot(Volume ~ Girth, data=trees)
mod.q <- lm(Volume ~ Girth + I(Girth^2) + Height + I(Height^2), data=trees)
summary(mod.q)
# alternative code:
mod.q <- lm(Volume ~ poly(Girth, 2, raw=TRUE) + poly(Height, 2, raw=TRUE), data=trees)
summary(mod.q)
plot(Volume ~ Girth, data=trees)
mod.q <- lm(Volume ~ Girth + I(Girth^2) + Height , data=trees)
summary(mod.q)
mod.int <- lm(Volume ~ Girth * Height, data=trees)
summary(mod.int)
mod <- lm(Volume ~ Girth + Height, data=trees)
plot(mod)
plot(trees$Volume ~ trees$Girth)
plot(trees$Volume ~ trees$Height)
library(sjPlot)
# plot_model(mod)
plot_model(mod, type = "eff", terms = "Girth")
library(MASS)
data(cats)
heads(cats)
head(cats)
str(cats)
plot(cats$Bwt, cats$Hwt)
plot(Bwt ~ Hwt, data=cats)
plot(Hwt ~ Bwt, data=cats)
cor(cats$Bwt, cats$Hwt) #coefficiente di correlazione (vicino a 1=correlate)
cor.test(cats$Bwt, cats$Hwt)
head(cats)
str(cats)
plot(cats$Bwt, cats$Hwt)
plot(Hwt ~ Bwt, data=cats) #to get the ~ you can search lm in help cuz they have it (just copy paste it)
cor(cats$Bwt, cats$Hwt) #coefficiente di correlazione (vicino a 1=correlate)
cor.test(cats$Bwt, cats$Hwt) #gives t-test too (it matters here cuz p-value<0.5 means it true, they correlated)
#to add this chunk you just gotta click the c+ button and choose R
mod <- lm(Hwt ~ Bwt, data=cats) #it is also ok to write cats$Bwt but inconvenient if you gotta reuse the formula
summary(mod)
plot(cats$Bwt, cats$Hwt)
abline(coef(mod), col="red")
plot(mod)
par(mfrow=c(2,2)) #this is to tell R we want to see the graphs on to 2 rows and 2 columns
plot(mod)
plot(mod)
plot(cats$Bwt, cats$Hwt)
abline(coef(mod), col="red")
```{r}
plot(cats$Bwt, cats$Hwt)
abline(coef(mod), col="red")
par(mfrow=c(2,2)) #this is to tell R we want to see the graphs on to 2 rows and 2 columns
plot(mod)
#ASSUNTI:
#correlazioni dei residui - primo grafico (no andamenti strani)
#normalità dei residui - secondo grafico (distribuzione su una retta)
#omogeneità della varianza dei residui - terzo grafico (più o meno stessa dispersione per i vari valori di x)
#quarto grafico è per verificare che non ci siano dati particolarmente influenti sull'analisi di regresione) (nuvola di cook, gott see what is inside-outside)
plot(mod)
library(car)
library(dplyr)
library(ggcorrplot)
install.packages("ggcorrplot")
library(car)
library(dplyr)
library(ggcorrplot)
install.packages("car")
library(car)
library(dplyr)
library(ggcorrplot)
install.packages("ggplot2")
library(car)
library(dplyr)
library(ggcorrplot)
library(car)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
# Load the data
data("Boston", package = "MASS")
# Split the data into training and test set
# set.seed(123)
# training.samples <- Boston$medv %>%
#   createDataPartition(p = 0.8, list = FALSE)
# train.data  <- Boston[training.samples, ]
# test.data <- Boston[-training.samples, ]
pred <- dplyr::select(Boston, crim:lstat)
names(pred)
pred
ggcorrplot(cor.matrix, method = "circle", lab=TRUE)
cor.matrix <- cor(pred)
cor.matrix
ggcorrplot(cor.matrix, method = "circle", lab=TRUE)
p.mat <- (abs(cor.matrix) > 0.7)
p.mat
# Build the model
model1 <- lm(medv ~ ., data = Boston) #to put . means correlazione con TUTTE le colonne nel dataset
summary(model1)
vif(model1)
pollution <- read.table("data/sulphur.dioxide.txt", header=TRUE)
dati.mod <- read.csv("data/dati.mod.csv")
head(dati.mod)
varexpl <- dati.mod[,8:15]
head(varexpl)
