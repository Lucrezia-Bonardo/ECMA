# non parametric test
wilcox.test(x,y,
paired = FALSE,
alternative = "two.sided")
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var.test(x,y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
t.test(x,y, var.equal=T)
x <- c(15,10,13,7, 9,8,21,9,14,8)
y <-  c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
t.test(x,y, var.equal=T)
wilcox.test(x,y, var.equal=T)
# non parametric test
?wilcox.test
wolcox.test(x,y, paired=T, var.equal=T, alternative="two.sided")
wilcox.test(x,y, paired=T, var.equal=T, alternative="two.sided")
library(dplyr)
## chi2 - goodness of fit test
freq <- c(22, 21, 22, 27, 22, 36)
probs <- rep(1/6, 6)
chisq.test(freq, p = probs)
## chi2 - test of independence
yesbelt <- c(12813, 647, 359, 42)
nobelt <- c(65963, 4000, 2642, 303)
chisq.test(data.frame(yesbelt, nobelt))
data.frame(yesbelt, nobelt)
rowSums(data.frame(yesbelt, nobelt))
colSums(data.frame(yesbelt, nobelt))
# for the first cell
78776*13861/sum(data.frame(yesbelt, nobelt))
# for the whole dataframe
n = sum(data.frame(yesbelt, nobelt))
data.frame(yesbelt, nobelt) %>%
mutate(somma.riga = rowSums(data.frame(yesbelt, nobelt)),
e.yesbelt = somma.riga*sum(yesbelt)/n,
e.nobelt = somma.riga*sum(nobelt)/n)
# compare with the values calculated by R
chisq.test(data.frame(yesbelt, nobelt))$exp
chisq.test(data.frame(yesbelt, nobelt))
## chi2 - test of independence
yesbelt <- c(12813, 647, 359, 42)
nobelt <- c(65963, 4000, 2642, 303)
chisq.test(data.frame(yesbelt, nobelt))
names(chisq.test(data.frame(yesbelt, nobelt)))
## chi2 - test of homogeneity
die.fair <- sample(1:6, 200, p=c(1,1,1,1,1,1)/6, replace = TRUE)
die.bias <- sample(1:6, 200, p=c(0.5,0.5,1,1,1,2)/6, replace = TRUE)
res.fair <- table(die.fair)
res.bias <- table(die.bias)
rbind(res.fair, res.bias)
chisq.test(rbind(res.fair, res.bias))
freq <- c(53, 22, 49)
probs <- c(5/12, 3/12, 4/12)
chisq.test(freq, p = probs)
Xsq$observed   # observed counts (same as M)
r1 <- c(3,1)
r2 <- c(1,0)
chisq.test(data.frame(r1,r2)) -> Xsq
Xsq$observed   # observed counts (same as M)
Xsq$expected
Xsq
Xsq$observed   # observed counts (same as M)
Xsq$expected
birds_habitats <- data.frame(
species = c("Ruby-crowed kinglet", "White-crowned sparrow", "Lincoln's sparrow",
"Golgen-crowded sparrow", "Bushtit", "Song sparrow", "Spotted towhee",
"Bewick's wren", "Hermit thrush", "Dard-eyed junco",
"Lesser goldfinch", "Uncommon"),
Remnant = c(677, 408, 270, 300, 198, 150, 137, 106, 119, 34, 57, 457),
Restored = c(198, 260, 187, 89, 91, 50, 32, 48, 24, 39, 15, 125)
)
birds_habitats
chisq.test(data.frame(birds_habitats$Remnant, birds_habitats$Restored))
u <- data.frame(yesbelt, nobelt)
u
res.fair
y<-rbind(res.fair, res.bias)
y
yesbelt
die.fair
res.fair
y
names(chisq.test(rbind(res.fair, res.bias)))
u
Xsq$observed   # observed counts (same as M)
Xsq$expected
Xsq$residuals
?chisq.test
growth = c(12, 10, 8, 11, 6, 7, 2, 3.5, 3.5)
tannin = 0:8
plot(growth ~ tannin)
abline(coef(lm.result), lwd=2, col="red")
lm.result <- lm(growth ~ tannin)
summary(lm.result)
plot(growth ~ tannin)
abline(coef(lm.result), lwd=2, col="red")
t = (-1.1583 - (-1.5))/0.2236
pt(t, 7, lower.tail = FALSE)
?pt
pt(t, 7, lower.tail = FALSE) #7=degrees of freedom, lower.tail=F check if it is larger (lower.tail=T check if it is same or less)
?confint
confint(lm.result) #confidence intervals (at 95%)
# ?cars
summary(cars)
cars.lm <- lm(dist ~ speed, data = cars)
names(cars.lm)
coef(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
summary(cars.lm)
?plot
plot(dist ~ speed, data = cars, pch = 16)
plot(dist ~ speed, data = cars)
cars.lm <- lm(dist ~ speed, data = cars, pch=16)
# ?cars
summary(cars)
cars.lm <- lm(dist ~ speed, data = cars)
names(cars.lm)
coef(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
summary(cars.lm)
-17.58 + 3.93 * (8) # point estimate
cars[5,] # real data
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
carsumry$sigma
summary(cars.lm)
confint(cars.lm)
# new <- data.frame(speed = c(5,6,21))
# predict(cars.lm, newdata = new, interval = "confidence")
# predict(cars.lm, newdata = new, interval = "prediction")
library(HH)
ci.plot(cars.lm)
# or
# library(UsingR)
# simple.lm(cars$speed, cars$dist, show.ci=TRUE)
x = c(18, 23, 25, 35, 65, 54, 34, 56, 72, 19, 23, 42, 18, 39, 37)
y = c(202, 186, 187, 180, 156, 169, 174, 172, 153, 199, 193, 174, 198, 183, 178)
lm(y ~ x) # the basic values of the regression analysis
lm.result = lm(y ~ x)
summary(lm.result)
plot(x,y, xlim=c(0,80), ylim=c(150,240)) # make a plot
plot(x,y, xlim=c(0,80), ylim=c(150,240)) # make a plot
abline(coef(lm.result)) #lm(y ~ x)) # plot the regression line
# to see only some parts of the result
coef(lm.result)
summary(resid(lm.result))
x = c(18, 23, 25, 35, 65, 54, 34, 56, 72, 19, 23, 42, 18, 39, 37)
y = c(202, 186, 187, 180, 156, 169, 174, 172, 153, 199, 193, 174, 198, 183, 178)
lm(y ~ x) # the basic values of the regression analysis
lm.result = lm(y ~ x)
summary(lm.result)
plot(x,y, xlim=c(0,80), ylim=c(150,240)) # make a plot
abline(coef(lm.result)) #lm(y ~ x)) # plot the regression line
# to see only some parts of the result
coef(lm.result)
summary(resid(lm.result))
# COMMENTED LINES - CALCULATIONS BY HAND, YOU CAN SKIP THEM AND USE THE OUTPUT OF THE REGRESSION ANALYSIS
# n = length(x)
# es = resid(lm.result)
# b1 = coef(lm.result)[[2]]
# s = sqrt(sum(es^2)/(n-2)) # S^2 = SSE/(n-2), s is the residual standard error
# SE = s/sqrt(sum((x-mean(x))^2)) # SE
b1 = -0.79773
SE = 0.06996
t = (b1-(-1))/SE # (obs. value - hyp.value)/SE
t
pt(t, 13, lower.tail = FALSE) # FIND THE RIGHT TAIL FOR THIS VALUE OF t AND 15-2 df
pt(t, 13, lower.tail = FALSE) # FIND THE RIGHT TAIL FOR THIS VALUE OF t AND 15-2 df
# COMMENTED LINES - CALCULATIONS BY HAND, YOU CAN SKIP THEM AND USE THE OUTPUT OF THE REGRESSION ANALYSIS
# SE.b0 = s*(sqrt((1/n)+(mean(x)^2/sum((x-mean(x))^2)))) # formula for the standard error of the intercept
SE.b0 = 2.86694
b0 = coef(lm.result)[[1]]
t = (b0 - 220)/SE.b0
t
pt(t, 13, lower.tail = TRUE) # FIND THE LEFT TAIL FOR THIS VALUE OF t AND 15-2 df
t = (-1.1583 - (-1.5))/0.2236 #slope 1 (tannin_estimate) - slope 2/ tannin_error given by lm
pt(t, 7, lower.tail = FALSE) #7=degrees of freedom, lower.tail=F check if it is larger (lower.tail=T check if it is same or less)
?pt
data(cars)
cars.lm <- lm(dist ~ speed, data = cars)
coef(cars.lm)
names(cars.lm)
residuals(cars.lm)
residuals(cars.lm)
par(mfrow=c(1,3))
hist(residuals(cars.lm))
boxplot(residuals(cars.lm))
qqnorm(residuals(cars.lm))
qqline(residuals(cars.lm))
par(mfrow=c(1,1))
plot(cars.lm)
# install.packages("lmtest")
library(lmtest)
dwtest(cars.lm, alternative = "two.sided")
cars[23,]
dim(cars)
dim(cars[-23,])
cars[-23,]
dim(cars[-23,])
shapiro.test(residuals(cars.lm))
shapiro.test(residuals(cars.lm))
library(lmtest)
bptest(cars.lm)
data("trees")
head(trees)
hist(trees$Volume)
hist(trees$Volume^2)
library(MASS)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
a
bctrans
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
bctrans
?boxcox
which(bctrans$y==max(bctrans$y))
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
which(bctrans$y==max(bctrans$y))
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
which(bctrans$y==max(bctrans$y))
bctrans$x[62]
hist(trees$Volume)
hist(trees$Volume^0.31)
max(bctrans$y)
library(dplyr)
risultati.bc <- data.frame(bctrans$y, bctrans$x)
head(risultati.bc)
arrange(risultati.bc, bctrans.y)
data("trees")
mod <- lm(Volume ~ Girth + Height, data=trees)
summary(mod)
Volume.tr <- trees$Volume^0.30
mod.tr <- lm(Volume.tr ~ Girth + Height, data=trees)
summary(mod.tr)
plot(Volume ~ Girth, data=trees)
mod.q <- lm(Volume ~ Girth + I(Girth^2) + Height + I(Height^2), data=trees)
summary(mod.q)
mod.q <- lm(Volume ~ Girth + I(Girth^2) + Height , data=trees)
summary(mod.q)
mod.int <- lm(Volume ~ Girth * Height, data=trees)
summary(mod.int)
plot(mod)
mod <- lm(Volume ~ Girth + Height, data=trees)
plot(mod)
plot(trees$Volume ~ trees$Girth)
plot(trees$Volume ~ trees$Height)
library(sjPlot)
# plot_model(mod)
plot_model(mod)
plot_model(mod, type = "eff", terms = "Girth")
plot_model(mod, type = "eff", terms = "Height")
plot_model(mod.int, type = "eff", terms = "Height")
plot_model(mod.int, type = "int", terms = c("Height","Girth")) # # type = "int" automatically selects groups for continuous moderator variables
library(jtools)
effect_plot(mod.int, pred = Girth, interval = TRUE)
plot_model(mod.int, type = "pred", terms = c("Girth", "Height [60,80]"))
# switch moderator
plot_model(mod.int, type = "pred", terms = c("Height", "Girth"))
?boxcox
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
which(bctrans$y==max(bctrans$y))
bctrans$x[58]
bctrans$x[62]
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
bctrans$x[62]
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 40))
which(bctrans$y==max(bctrans$y))
bctrans
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
bctrans
knitr::opts_chunk$set(echo = TRUE)
trees$Tall <- cut(trees$Height, breaks = c(-Inf, 76, Inf),
labels = c("no", "yes"))
trees$Tall[1:5]
class(trees$Tall)
treesdummy.lm <- lm(Volume ~ Girth + Tall, data = trees)
summary(treesdummy.lm)
# # we split the trees data into
# # two pieces, with groups determined by the Tall variable:
treesTall <- split(trees, trees$Tall)
# # we add the Fitted values to each
# # piece via predict
treesTall[["yes"]]$Fit <- predict(treesdummy.lm, treesTall[["yes"]])
treesTall[["no"]]$Fit <- predict(treesdummy.lm, treesTall[["no"]])
# # we set up a plot for the variables Volume versus Girth
# # but we do not
# # plot anything yet (type = n) because we want to use different symbols for the two groups
plot(Volume ~ Girth, data = trees, type = "n")
# # we add points to the plot for the Tall = yes trees and use an open circle for a plot character
# # (pch = 1), followed by points for the Tall = no trees with a triangle character (pch = 2).
points(Volume ~ Girth, data = treesTall[["yes"]], pch = 1)
plot(Volume ~ Girth, data = trees, type = "n")
# # we add points to the plot for the Tall = yes trees and use an open circle for a plot character
# # (pch = 1), followed by points for the Tall = no trees with a triangle character (pch = 2).
points(Volume ~ Girth, data = treesTall[["yes"]], pch = 1)
points(Volume ~ Girth, data = treesTall[["no"]], pch = 2)
plot(Volume ~ Girth, data = trees, type = "n")
# # we add points to the plot for the Tall = yes trees and use an open circle for a plot character
# # (pch = 1), followed by points for the Tall = no trees with a triangle character (pch = 2).
points(Volume ~ Girth, data = treesTall[["yes"]], pch = 1)
points(Volume ~ Girth, data = treesTall[["no"]], pch = 2)
# # we add regression lines to the plot, one for each group
lines(Fit ~ Girth, data = treesTall[["yes"]])
lines(Fit ~ Girth, data = treesTall[["no"]])
plot(Volume ~ Girth, data = trees)
abline(a = -34, b = 4.69, col="red") # alberi bassi
abline(a = -30, b = 4.69, col="blue") # alberi alti
data(PlantGrowth)
plant.df = PlantGrowth
plant.df$group = factor(plant.df$group, labels = c("Control", "Treatment 1", "Treatment 2"))
str(plant.df)
hist(plant.df$weight)
shapiro.test(plant.df$weight)
qqnorm(plant.df$weight); qqline(plant.df$weight)
boxplot(weight ~ group, data = plant.df)
mod <- lm(weight ~ group, data = plant.df)
summary(mod)
plant.df$group <- relevel(plant.df$group, ref="Treatment 1")
mod <- lm(weight ~ group, data = plant.df)
summary(mod)
summary(aov(weight ~ group, data=plant.df))
anova(lm(weight ~ group, data=plant.df))
mydata <- read_excel("data/CawRidge_LifetimeData.xlsx")
# library(tidyverse)
library(dplyr)
library(ggplot2)
library(readxl)
library(HH)
library(Rmisc)
mydata <- read_excel("data/CawRidge_LifetimeData.xlsx")
head(mydata)
# table(is.na(mydata$densityYOB))
mydata$densityYOB <- as.numeric(mydata$densityYOB)
# table(is.na(mydata$densityYOB))
table(is.na(mydata$densityYOB))
mydata$densityYOB <- as.numeric(mydata$densityYOB)
mydata %>%
dplyr::select(densityYOB, longevity, ALR) %>%
mutate(repr = "yes") %>%
na.omit() -> mydata
mydata$repr[mydata$ALR == "never"] <- "no"
mydata$repr <- as.factor(mydata$repr)
mydata %>%
filter(repr == "yes") -> mydata_repr
mydata %>%
filter(repr == "no") -> mydata_norepr
boxplot(longevity ~ repr, data=mydata)
shapiro.test(x)
x <- c(15,10,13,7, 9,8,21,9,14,8)
y <-  c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
shapiro.test(x)
var.test(x,y)
var(x, na.rm = T)
var(y, na.rm = T)
qqnorm(mydata_norepr); qqline(mydata_norepr, col="red")
shapiro.test(mydata_norepr)
var.test(mydata_repr, mydata_norepr)
t.test(mydata_repr, mydata_norepr)
long_repr<-(mydata_repr$longevity)
long_repr
long_norepr<-(mydata_norepr$longevity)
shapiro.test(long_norepr)
shapiro.test(long_repr)
qqnorm(long_repr); qqline(long_repr, col="red")
shapiro.test(long_norepr)
qqnorm(long_norepr); qqline(long_norepr, col="red")
var.test(long_norepr, long_repr)
t.test(long_norepr, long_repr, var.equal = T)
wilcox.test(long_norepr, long_repr, var.equal = T)
?confint
confint(long_norepr)
confint(mydata_norepr, "longevity")
t.test(long_norepr, long_repr, var.equal = T)
results<-t.test(long_norepr, long_repr, var.equal = T)
results$conf.int
t.test(long_norepr)
t.test(long_repr)
notest<-t.test(long_norepr)
yestest<-t.test(long_repr)
notest$conf.int
yestest$conf.int
notest$conf.int
yestest$conf.int
?lm
lm(longevity ~ densityYOB, data = mydata)
?plot
plot(longevity ~ densityYOB, data = mydata)
plot(lm(longevity ~ densityYOB, data = mydata))
?fitted
plot(longevity ~ densityYOB, data = mydata)
plot(longevity ~ densityYOB, data = mydata)
abline(a = 16.3, b = -0.06, col="red")
summary(lm(longevity ~ densityYOB, data = mydata))
den.lm<-lm(longevity ~ densityYOB, data = mydata)
predict(dan.lm, newdata = data.frame(densityYOB == 130))
predict(den.lm, newdata = data.frame(densityYOB == 130))
predict(den.lm, newdata = densityYOB==130 )
plot(longevity ~ densityYOB, data = mydata)
abline(a = 16.3, b = -0.06, col="red")
lm(densityYOB ~ longevity, data = mydata)
den.lm<-lm(densityYOB ~ longevity, data = mydata)
plot(den.lm)
abline(a = 146, b = -2.305, col="red")
plot(densityYOB ~ longevity, data = mydata)
abline(a = 146, b = -2.305, col="red")
lm(longevity ~ densityYOB, data = mydata)
den.lm<-lm(longevity ~ densityYOB, data = mydata)
plot(longevity ~ densityYOB, data = mydata)
abline(a = 16.3, b = -0.06, col="red")
16.3-0.06*(130)
which(mydata$densityYOB==130)
mydata$densityYOB
which(mydata$densityYOB==138)
16.3-0.06*(130)
plot(den.lm)
summary(lm(longevity ~ densityYOB, data = mydata))
library(HH)
ci.plot(den.lm)
shapiro.test(long_repr)
shapiro.test(long_norepr)
var.test(long_norepr, long_repr)
notest<-wilcox.test(long_norepr)
yestest<-wilcox.test(long_repr)
notest$conf.int
yestest$conf.int
long_repr<-(mydata_repr$longevity)
long_norepr<-(mydata_norepr$longevity)
notest<-wilcox.test(long_norepr)
yestest<-wilcox.test(long_repr)
notest$conf.int
yestest$conf.int
#t.test(long_norepr, long_repr, var.equal = T) #necessita normalità, non applicabile a questo caso
wilcox.test(long_norepr, long_repr, var.equal = T) #applicabile a distribuzione non normale
results<-wilcox.test(long_norepr, long_repr, var.equal = T)
results$conf.int
summary(results)
wilcox.test(long_norepr, long_repr, var.equal = T) #applicabile a distribuzione non normale
wilcox.test(long_norepr, long_repr, var.equal = F)
#t.test(long_norepr, long_repr, var.equal = T) #necessita normalità, non applicabile a questo caso
wilcox.test(long_norepr, long_repr, var.equal = T) #applicabile a distribuzione non normale
boxplot(longevity ~ repr, data=mydata)
mean(long_norepr)
dim(long_norepr)
size(long_norepr)
?dim
long_norepr
dim(long_norepr)
dim(mydata_norepr$longevity)
dim(mydata_norepr)
sd(long_norepr)
mean(long_norepr)+0.95*(sd(long_norepr)/sqrt(27))
mean(long_norepr)-0.95*(sd(long_norepr)/sqrt(27))
t.test(long_norepr)
mean(long_norepr)+0.95*(sd(long_norepr)/sqrt(27))
mean(long_norepr)-0.95*(sd(long_norepr)/sqrt(27))
t.test(long_norepr)
dim(mydata_repr$longevity)
dim(mydata_repr)
mean(long_repr)+0.95*(sd(long_repr)/sqrt(76))
mean(long_repr)-0.95*(sd(long_repr)/sqrt(76))
t.test(long_repr)
mean(long_norepr)+0.95*(sd(long_norepr)/sqrt(27))
mean(long_norepr)-0.95*(sd(long_norepr)/sqrt(27))
t.test(long_norepr)
?t.test
#t.test(long_norepr, long_repr, var.equal = T) #necessita normalità, non applicabile a questo caso
wilcox.test(long_norepr, long_repr, var.equal = T, alternative = c("two.sided")) #applicabile a distribuzione non normale
#dim(mydata_norepr) #trova valore n
#mean(long_norepr)+0.95*(sd(long_norepr)/sqrt(27)) #4.73
#mean(long_norepr)-0.95*(sd(long_norepr)/sqrt(27)) #3.94
t.test(long_norepr) #5.19 - #3.48
CI(long_norepr, ci= 0.95)
CI(long_repr, ci= 0.95)
lm(longevity ~ densityYOB, data = mydata)
summary(lm(longevity ~ densityYOB, data = mydata))
